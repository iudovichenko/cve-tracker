
import configparser
import logging
import json
import os
import re
import tempfile
import threading
import yaml
import queue

from git import Repo

from debian import deb822
from debian.changelog import Changelog
from lib.config import CONFIG

from pyrpm.spec import Spec


class GitRepo(object):
    log = logging.getLogger(__name__)

    def __init__(self, repo=None, store_prefix=None, git_prefix=None):
        self._ = repo
        self.store_prefix = store_prefix
        self.git_prefix = git_prefix

    def import_project(self, project, branch='master', fetch=True):
        self._ = None
        self.log.info("Importing project '{}' ...".format(project))
        target_path = os.path.join(self.store_prefix, project)
        os.makedirs(target_path, exist_ok=True)
        if not os.path.exists(os.path.join(target_path, '.git')):
            self.log.info("Creating new repo '{}' at '{}' ..."
                         .format(project, target_path))
            self._ = Repo.init(target_path)
            origin = self.remote('origin', self.git_prefix + '/' + project)
            fetch = True
        else:
            self.log.info("Using existing repo at '{}' ..."
                         .format(target_path))
            self._ = Repo(target_path)
            origin = self.remote('origin')

        if fetch:
            origin.fetch()

        self.checkout(branch)

    def remote(self, name, url=None):
        remote = getattr(self._.remotes, name, None)
        if remote is None:
            remote = self._.create_remote(name, url)

        return remote

    def deep_clean(self):
        self.log.info("Performing deep repo clean ...")
        git = self._.git
        git.clean('-f', '-d', '-x')
        first_commit = git.rev_list('--max-parents=0', 'HEAD').split('\n')[0]
        git.reset('--hard', first_commit)
        git.checkout('master')
        git.pull()

    def checkout(self, branch='master'):
        self.log.info("Checkout branch '{}' ...".format(branch))
        if self._.is_dirty():
            self.deep_clean()

        if branch in self._.heads:
            self._.heads[branch].checkout()
        else:
            origin = self._.remotes.origin
            if branch not in origin.refs:
                origin.fetch()
            self._.create_head(branch, origin.refs[branch])\
                .set_tracking_branch(origin.refs[branch]).checkout()
            self._.git.pull()


class DebianVersion(object):
    def __init__(self, version):
        self.epoch = 0
        self.version = ''
        self.revision = ''
        self.suffix = ''
        self.mos_distribution = ''
        self.mos_suffix = ''
        self.full_version = version

        l = self.full_version.split(':', maxsplit=1)
        if len(l) == 2:
            self.epoch = l.pop(0)

        re_version = r'^(.*)(~u\d{2}\.?\d{2})(.*)$'
        match = re.match(re_version, l[0])
        if match:
            self.version = match.group(1)
            self.mos_distribution = match.group(2)
            self.mos_suffix = match.group(3)
        else:
            self.version = l[0]
        l = self.version.split('-', maxsplit=1)
        if len(l) == 2:
            self.version = l.pop(0)
        self.revision = l[0]

        dfsg_version = r'^(.*)([+-]dfsg.*)$'
        match = re.match(dfsg_version, self.version)
        if match:
            self.version = match.group(1)
            self.suffix = match.group(2)


class GitProjectScanner(object):
    def __init__(self, *args, configfile=None, filename='packages.json',
                 thread_count=10, **kwargs):
        self.log = logging.getLogger()
        self.configfile = configfile or CONFIG.configfile
        self.filename = filename
        self.threads = []
        self.thread_count = thread_count

    def start(self):
        result_queue = queue.Queue()
        result_queue.empty()

        producer = GitProjectScannerProducer(
            name='Producer',
            thread_count=self.thread_count,
            configfile=self.configfile,
            result_queue=result_queue,
        )

        consumer = GitProjectScannerConsumer(
            name='Consumer',
            configfile=self.configfile,
            filename=self.filename,
            result_queue=result_queue,
        )

        producer.start()
        consumer.start()
        producer.join()
        consumer.disable()
        consumer.join()


class BaseThread(threading.Thread):
    def __init__(self, *args, name=None, configfile=None, **kwargs):
        super().__init__(*args, name=name, **kwargs)
        self.log = logging.getLogger(self.name)
        self.configfile = configfile
        self.config = configparser.ConfigParser(os.environ)
        self.config.read(configfile)
        self.enabled = True

    def disable(self):
        self.enabled = False


class GitProjectScannerProducer(BaseThread):
    def __init__(self, *args, thread_count=1, result_queue=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.thread_count = thread_count
        self.threads = []
        self.task_queue = queue.Queue(self.thread_count)
        self.task_queue.empty()
        self.result_queue = result_queue
        self.products = yaml.load(open(self.config.get('common',
                                                       'product_list')))

    def run(self):
        self.start_threads()
        self.produce_data()
        self.stop_threads()

    def start_threads(self):
        for id in range(self.thread_count):
            t = GitProjectScannerWorker(
                name='Worker-{}'.format(id),
                configfile=self.configfile,
                task_queue=self.task_queue,
                result_queue=self.result_queue
            )
            self.threads.append(t)
            t.start()

    def stop_threads(self):
        for t in self.threads:
            t.disable()

        for t in self.threads:
            self.log.info('Joining thread {}'.format(t.name))
            t.join()
            self.log.info('Thread {} stopped'.format(t.name))

    def produce_data(self):
        for project in self.projects():
            task = {
                'data': [],
            }
            for data in self.matched_products(project):
                task['data'].append({
                    'project': project,
                    'product_data': data,
                })
            self.log.info('[{}] Sending data to task_queue'.format(self.name))
            self.task_queue.put(task)

        print('All data have been sent to task_queue')

    def projects(self, pattern='.*'):
        projects_source = self.config.get('projects', 'source')
        if projects_source == 'jeepyb_config':
            repo = GitRepo(
                store_prefix=self.config.get('git', 'store_prefix'),
                git_prefix=self.config.get('git', 'url_prefix'),
            )
            repo.import_project(
                self.config.get('projects', 'jeepyb_config'),
            )
            projects = yaml.load(open(
                os.path.join(repo._.working_dir, 'projects.yaml')))
        elif projects_source == 'projects_yaml':
            projects = yaml.load(
                open(self.config.get('projects', 'projects_yaml')))
        else:
            raise Exception("Can't find source for projects.yaml")

        for project in projects:
            if re.match(pattern, project['project']):
                yield project['project']

    def matched_products(self, project):
        for data in self.products:
            product_data = {}
            for key, value in data.items():
                if key in ['projects', ]:
                    continue
                product_data[key] = value
            for project_data in data.get('projects', []):
                if re.match(project_data['pattern'], project):
                    data = {}
                    data.update(product_data)
                    data.update(project_data)
                    yield data


class GitProjectScannerConsumer(BaseThread):
    def __init__(self, *args, result_queue=None, filename='packages.json',
                 **kwargs):
        super().__init__(*args, **kwargs)
        self.result_queue = result_queue
        self.filename = filename

    def run(self):
        logging.info('[{}] Starting consumer'.format(self.name))
        while self.enabled:
            try:
                task = self.result_queue.get(timeout=1.0)
            except queue.Empty:
                continue
            if task is None:
                continue
            self.log.info("[{}] Got task from result_queue".format(self.name))
            data = task.get('data', {})

            with open(self.filename, 'a') as ofile:
                ofile.write('{}\n'.format(json.dumps(data)))


class GitProjectScannerWorker(BaseThread):
    def __init__(self, *args, task_queue=None, result_queue=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.task_queue = task_queue
        self.result_queue = result_queue
        self.parser = GitProjectParser(
            store_prefix=self.config.get('git', 'store_prefix'),
            git_prefix=self.config.get('git', 'url_prefix'),
        )

    def run(self):
        while self.enabled:
            try:
                task = self.task_queue.get(timeout=1.0)
            except queue.Empty:
                continue
            if task is None:
                continue
            self.log.info("[{}] Got task from task_queue"
                          .format(self.name, task))
            data = task.get('data', {})

            for data_ in data:
                try:
                    result = {}
                    project = data_.get('project', None)
                    product_data = data_.get('product_data', {})
                    if product_data.get('type', None) == 'deb':
                        result = self.parser.parse_deb_project(
                            project, product_data)
                    if product_data.get('type', None) == 'rpm':
                        result = self.parser.parse_rpm_project(
                            project, product_data)

                    self.log.info('[{}] Sending data to result_queue'
                                  .format(self.name))
                    self.result_queue.put({
                        'data': result,
                        'worker': self.name
                    })
                except Exception as e:
                    self.log.exception(e)


class GitProjectParser(object):
    def __init__(self, store_prefix=None, git_prefix=None):
        self.repo = GitRepo(store_prefix=store_prefix,
                            git_prefix=git_prefix)

    def parse_deb_project(self, project, product_data):
        if product_data['type'] != 'deb':
            return project

        project_data = {
            'product': {
                'name': product_data['name'],
                'version': product_data['version'],
            },
            'distribution': {
                'name': '',
                'version': '',
                'arch': '',
                'alias': product_data['distribution'],
            },
            'product_distribution': {
                'name': '',
                'version': '',
                'arch': '',
                'alias': product_data['distribution'],
            },
            'spec_project': '',
            'source_project': '',
            'branch': product_data['branch'],
            'type': product_data['type'],
        }

        self.repo.import_project(project, branch=product_data['branch'])

        spec_path = product_data['spec-dirs'][0]
        changelog_file = os.path.join(self.repo._.working_dir,
                                      spec_path, 'changelog')
        control_file = os.path.join(self.repo._.working_dir,
                                    spec_path, 'control')
        series_file = os.path.join(self.repo._.working_dir,
                                   spec_path, 'patches/series')

        source_packages = []
        binary_packages = []

        if os.path.exists(control_file):
            for para in deb822.Sources.iter_paragraphs(open(control_file),
                                                       use_apt_pkg=False):
                if 'Source' in para:
                    source_packages.append(para)
            for para in deb822.Packages.iter_paragraphs(open(control_file),
                                                        use_apt_pkg=False):
                if 'Package' in para:
                    binary_packages.append(para)
        else:
            raise Exception("Control file '{}' not found".format(control_file))

        if os.path.exists(changelog_file):
            changelog = Changelog(open(changelog_file), strict=False)
        else:
            raise Exception(
                "Changelog file '{}' not found".format(changelog_file))

        project_data['spec_project'] = project
        project_data['source_project'] = project.replace('-build', '')

        project_data['source_package'] = source_packages[0]['Source']
        project_data['section_name'] = source_packages[0]['Section']

        for key in ['Build-Depends', 'Build-Depends-Indep']:
            for dep in map(lambda s: s.strip(),
                           source_packages[0].get(key, '').split(',')):
                dep = '|'.join(
                    map(lambda s: s.split()[0] if s else '', dep.split('|')))
                if dep:
                    project_data.setdefault('build_depends', []).append(dep)

        if os.path.exists(series_file):
            for patch_name in open(series_file):
                patch_name = patch_name.rstrip()
                if re.match(r'^\s*#', patch_name):
                    continue
                matches = re.findall(
                    r'(?:^|[\/_-])([Cc][Vv][Ee](?:\d{4,}|[_-])+)[\.-]',
                    patch_name)
                for m in matches:
                    project_data.setdefault('cves', []).append(m)

        project_data.setdefault('version', {})
        project_data['version'] = {
            'epoch': changelog.epoch or 0,
            'version': changelog.debian_version,
            'revision': changelog.debian_revision,
            'full_version': changelog.full_version
        }
        project_data['upstream_version'] = changelog.upstream_version

        for block in changelog:
            project_data['distribution_version'] = block.version.full_version
            if re.match(r'.*\@(ubuntu|canonical)\.com.*', block.author):
                project_data['distribution']['alias'] = block.distributions
                if 'cloud' in block.version.full_version:
                    project_data['package_origin'] = 'Ubuntu Cloud Archive'
                else:
                    project_data['package_origin'] = 'Ubuntu'
                break
            if re.match(r'.*\@debian\.org.*', block.author):
                project_data['distribution']['alias'] = block.distributions
                project_data['package_origin'] = 'Debian'
                break
        else:
            project_data['package_origin'] = 'Mirantis'

        for package in binary_packages:
            pkg = {}
            pkg['name'] = package['Package']
            for dep in map(lambda s: s.strip(),
                           package.get('Depends', '').split(',')):
                dep = '|'.join(
                    map(lambda s: s.split()[0] if s else '', dep.split('|')))
                if dep:
                    pkg.setdefault('depends', []).append(dep)
            project_data.setdefault('binary_packages', []).append(pkg)

        return project_data

    def parse_rpm_project(self, project, product_data):
        if product_data['type'] != 'rpm':
            return project

        project_data = {
            'product': {
                'name': product_data['name'],
                'version': product_data['version'],
            },
            'distribution': {
                'name': '',
                'version': '',
                'arch': '',
                'alias': product_data['distribution'],
            },
            'product_distribution': {
                'name': '',
                'version': '',
                'arch': '',
                'alias': product_data['distribution'],
            },
            'spec_project': '',
            'source_project': '',
            'branch': product_data['branch'],
            'type': product_data['type'],
        }

        self.repo.import_project(project, branch=product_data['branch'])

        spec_path = product_data.get('spec-dirs', ['.', ])[0]
        spec_dir = os.path.join(self.repo._.working_dir, spec_path)
        for file in os.listdir(spec_dir):
            if file.endswith('.spec'):
                spec_file = os.path.join(spec_dir, file)
                break

        temp_file = tempfile.mktemp()
        cmd = 'rpmspec --parse {} > {}'.format(spec_file, temp_file)
        os.system(cmd)
        spec = Spec.from_file(temp_file)

        sources = []
        binary_packages = []

        project_data['spec_project'] = project
        project_data['source_project'] = project.replace('-build', '')

        for name in spec.sources:
            sources.append(name)

        for package in spec.packages:
            binary_packages.append(package.name)

        project_data['version'] = {
            'epoch': spec.epoch or 0,
            'version': spec.version,
            'revision': spec.release,
            'full_version': '',
        }
        fmt = '{0[version][epoch]}:{0[version][version]}-{0[version][revision]}'
        project_data['version']['full_version'] = fmt.format(project_data)
        project_data['upstream_version'] = project_data['version']['version']

        project_data['package_origin'] = 'Undefined'

        project_data['source_package'] = binary_packages.pop(0)
        for name in binary_packages:
            project_data.setdefault('binary_packages', []).append(name)

        for name in spec.patches:
            project_data.setdefault('patches', []).append(name)

        os.remove(temp_file)
        return project_data
