from cpe import CPE
import json
import logging
import yaml
import zlib
import re
import os
try:
    import urllib2
except ImportError:
    import urllib.request as urllib2

BASE_URL = 'https://static.nvd.nist.gov/feeds/json/'\
           'cve/1.0/nvdcve-1.0-{}.json.gz'


class Node(object):
    log = logging.getLogger(__name__)

    def __init__(self, node):
        self.cpes = list()
        self.hws = list()
        self.oss = list()
        self.apps = list()
        self.node = node
        if self.node['operator'] == 'AND':
            for child in self.node.get('children', []):
                node = Node(child)
                self.cpes += node.cpes
        else:
            for cpe in self.node.get('cpe', []):
                self.cpes.append(cpe['cpe23Uri'])

    def get_cpe_info(self, cpe):
        part = cpe.get_part()[0]
        vendor = cpe.get_vendor()[0]
        product = cpe.get_product()[0]
        version = cpe.get_version()[0]
        return part, vendor, product, version

    def parse(self):
        for cpe in self.cpes:
            try:
                _cpe = CPE(cpe)
                part, vendor, product, version = self.get_cpe_info(_cpe)
                if part == 'h':
                    self.hws.append((vendor, product))
                elif part == 'o':
                    self.oss.append((vendor, product))
                elif part == 'a':
                    self.apps.append((vendor, product))
            except NotImplementedError:
                self.log.error('Something is wrong with cpe: {}'.format(cpe))


class FeedParser(object):
    log = logging.getLogger(__name__)

    def __init__(self, feed_filter=None):
        self.config = {
            'hwfilter': list(),
            'osfilter': list(),
        }
        if feed_filter:
            with open(feed_filter, 'r') as f:
                filter_data = yaml.safe_load(f.read())
                for key in ('hwfilter', 'osfilter'):
                    self.config[key].extend(filter_data.get(key, list()))

    def load_content(self, url):
        try:
            body = urllib2.urlopen(url, timeout=30).read()
            content = json.loads((zlib.decompress(
                                  body, zlib.MAX_WBITS | 32)).decode('utf-8'))
        except:
            self.log.error("Failed to download feed from '{}'".format(url))
            raise
        return content

    def parse_feed(self, name):
        url = BASE_URL.format(name)
        self.log.info("Parsing feed '{}'".format(url))
        feed = self.load_content(url)
        cves = list()
        hwfilter = self.config['hwfilter']
        osfilter = self.config['osfilter']
        for item in feed['CVE_Items']:
            cveid = item['cve']['CVE_data_meta']['ID']
            dropcount = 0
            nodescount = len(item['configurations']['nodes'])
            for node in item['configurations']['nodes']:
                n = Node(node)
                n.parse()
                if hwfilter:
                    hws = list()
                    if len(n.hws) > 0:
                        for v, p in n.hws:
                            if v in ('*', '-') or v not in hwfilter:
                                hws.append(v)
                        if len(hws) == 0:
                            dropcount += 1
                if osfilter:
                    oss = list()
                    if len(n.oss) > 0:
                        for v, p in n.oss:
                            if v not in osfilter:
                                oss.append(v)
                        if len(oss) == 0:
                            dropcount += 1
            if nodescount > dropcount:
                cves.append(item)
            else:
                self.log.debug("Skip {} due to filter restrictions"
                              .format(cveid))
        return cves

    def store_feeds(self, feeds=list(), tmpdir='/tmp'):
        for feed in feeds:
            if re.match('^\d+$', feed) or feed in ('recent', 'modified'):
                cves = self.parse_feed(feed)
                feedfile = os.path.join(tmpdir, 'feed-{}.json'.format(feed))
                with open(feedfile, 'w') as f:
                    json.dump(cves, f, indent=2)
                yield feedfile
            else:
                self.log.warning("Bad feed name '{}'".format(feed))
